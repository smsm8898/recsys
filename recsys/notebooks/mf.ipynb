{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a49f2e00-2159-4081-91df-a8417ee4019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from recsys.models import MF\n",
    "from recsys.data.movielens import MovielensSimpleDataset\n",
    "from recsys.metrics.rank import hit_ratio_at_k, ndcg_at_k, mrr_at_k\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e75207-eaad-4df8-bd1d-5cbb9588863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"movielens/processed/num_sparse_features.json\", \"r\") as f:\n",
    "    num_sparse_features = json.load(f)\n",
    "    \n",
    "with open(\"movielens/processed/experiment_group.json\", \"r\") as f:\n",
    "    experiment_group = json.load(f)\n",
    "experiment_group[MF.model_name] = []\n",
    "\n",
    "train = np.load(\"movielens/processed/train.npy\")\n",
    "test = np.load(\"movielens/processed/test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4b1fcf0-ddd3-45f2-aacf-4a8e5a6f5920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixFactorization(\n",
      "  (embeddings): ModuleDict(\n",
      "    (user_id): Embedding(943, 16)\n",
      "    (item_id): Embedding(1682, 16)\n",
      "    (gender): Embedding(2, 16)\n",
      "    (occupation): Embedding(21, 16)\n",
      "    (genre): Embedding(19, 16)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Training Hyperparameter\n",
    "batch_size = 64\n",
    "latent_dim = 16\n",
    "lr = 1e-3\n",
    "epochs = 10\n",
    "\n",
    "# Define Dataset\n",
    "train_ds = MovielensSimpleDataset(train, list(num_sparse_features.keys()))\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = MF(num_sparse_features, latent_dim)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d11ed-1e00-4e76-a6e9-1dc81b1d7b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|█| 5747/5747 [00:09<00:00, 608.71it/s, auc=0.0000, logloss=1.03\n",
      "Epoch 2/10: 100%|█| 5747/5747 [00:09<00:00, 588.21it/s, auc=0.5006, logloss=0.70\n",
      "Epoch 3/10: 100%|█| 5747/5747 [00:10<00:00, 523.96it/s, auc=0.5190, logloss=0.63\n",
      "Epoch 4/10: 100%|█| 5747/5747 [00:11<00:00, 513.02it/s, auc=0.5651, logloss=0.35\n",
      "Epoch 5/10: 100%|█| 5747/5747 [00:11<00:00, 495.46it/s, auc=0.6994, logloss=0.18\n",
      "Epoch 6/10: 100%|█| 5747/5747 [00:12<00:00, 474.14it/s, auc=0.8157, logloss=0.36\n",
      "Epoch 7/10: 100%|█| 5747/5747 [00:11<00:00, 481.49it/s, auc=0.8560, logloss=0.45\n",
      "Epoch 8/10: 100%|█| 5747/5747 [00:12<00:00, 465.77it/s, auc=0.8807, logloss=0.21\n",
      "Epoch 9/10: 100%|█| 5747/5747 [00:11<00:00, 488.78it/s, auc=0.8997, logloss=0.31\n",
      "Epoch 10/10:  72%|▋| 4157/5747 [00:08<00:03, 509.39it/s, auc=0.9125, logloss=0.2"
     ]
    }
   ],
   "source": [
    "# Train MF\n",
    "history = defaultdict(list)\n",
    "model.train()\n",
    "auc = 0\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for sparse_features, labels in pbar:\n",
    "        sparse_features = {k: v.to(device) for k, v in sparse_features.items()}\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        \n",
    "        # forward\n",
    "        logits = model(sparse_features)\n",
    "        loss = torch.nn.functional.binary_cross_entropy_with_logits(logits, labels)\n",
    "\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # metrics\n",
    "        total_loss += loss.item()\n",
    "        probs = logits.sigmoid().detach().cpu().numpy()\n",
    "        all_preds.extend(probs.flatten())\n",
    "        all_labels.extend(labels.detach().cpu().numpy().flatten())\n",
    "        \n",
    "        # tqdm update\n",
    "        pbar.set_postfix(\n",
    "            logloss=loss.item(),\n",
    "            auc=f\"{auc:.4f}\"\n",
    "            \n",
    "        )\n",
    "\n",
    "        \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    acc = ((np.array(all_preds) > 0.5) == np.array(all_labels)).mean()\n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "    history[\"accuracy\"].append(acc)\n",
    "    history[\"auroc\"].append(auc)\n",
    "    history[\"logloss\"].append(avg_loss)\n",
    "    \n",
    "    pbar.set_postfix(\n",
    "        logloss=f\"{avg_loss:.4f}\",\n",
    "        auc=f\"{auc:.4f}\"\n",
    "    )\n",
    "    pbar.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c9dea-5635-405e-bd2b-cf8b9bc984f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=False)\n",
    "\n",
    "for i, metrics in enumerate(history):\n",
    "    ax = axes[i]\n",
    "\n",
    "    ax.plot(range(1, epochs+1), history[metrics], marker=\"o\", label=metrics)\n",
    "    ax.set_title(metrics.upper())\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(metrics)\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff35620-4791-4484-825b-bbf9d3571748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation\n",
    "user_recommendations = {}\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    all_item_indices = torch.arange(num_sparse_features[\"item_id\"]).to(device)\n",
    "    pbar = tqdm(range(num_sparse_features[\"user_id\"]), desc=\"Recommend\")\n",
    "    for user_id in pbar:\n",
    "        sparse_features = {\n",
    "            \"user_id\":torch.full(size=(len(all_item_indices),), fill_value=user_id).to(device),\n",
    "            \"item_id\":all_item_indices,\n",
    "        }\n",
    "        logits = model(sparse_features)\n",
    "        indices = logits.flatten().argsort(descending=True)\n",
    "        \n",
    "\n",
    "        user_recommendations[user_id] = indices.detach().cpu().numpy()\n",
    "\n",
    "        pbar.set_postfix(user_id=user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed2fe3-62ef-4c7c-a93b-fee19d16d389",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [5, 10, 15, 20]\n",
    "hr = defaultdict(float)\n",
    "ndcg = defaultdict(float)\n",
    "mrr = defaultdict(float)\n",
    "\n",
    "for line in test:\n",
    "    user_id, item_id, _ = line\n",
    "    recs = user_recommendations[user_id]\n",
    "    experiment_group[model.model_name] = recs\n",
    "\n",
    "    # calculate\n",
    "    for k in ks:\n",
    "        for m in experiment_group:\n",
    "            hr[f\"{m}@{k}\"] += hit_ratio_at_k(experiment_group[m], item_id, k)\n",
    "            ndcg[f\"{m}@{k}\"] += ndcg_at_k(experiment_group[m], item_id, k)\n",
    "            mrr[f\"{m}@{k}\"] += mrr_at_k(experiment_group[m], item_id, k)\n",
    "    \n",
    "    \n",
    "hr = {k: np.round(v/len(test), 4) for k,v in hr.items()}\n",
    "ndcg = {k: np.round(v/len(test), 4) for k,v in ndcg.items()}\n",
    "mrr = {k: np.round(v/len(test), 4) for k,v in mrr.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df7feb3-caaf-4d1c-8758-4a547bc2adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\"HR\": hr, \"NDCG\": ndcg, \"MRR\": mrr}\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=False)\n",
    "\n",
    "for ax, (metric_name, metric_dict) in zip(axes, metrics.items()):\n",
    "    for m in experiment_group:\n",
    "        values = [metric_dict[f\"{m}@{k}\"] for k in ks]\n",
    "        ax.plot(ks, values, marker=\"o\", label=m)\n",
    "\n",
    "    ax.set_title(metric_name.upper())\n",
    "    ax.set_xlabel(\"K\")\n",
    "    ax.set_ylabel(metric_name)\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d859a844-55c7-4237-a85e-eb13a5b3efbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5018613d-b7f9-4463-b24e-ed12fc8648e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
